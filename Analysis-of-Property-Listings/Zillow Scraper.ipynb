{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait as wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating the Webdriver\n",
    "I used Selenium + chromedriver to open an automated webdriver for chrome. To get information from the pages, I used a combination of BeautifulSoup and Selenium driver functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agents = pd.read_csv('agents.csv')\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001160C28E2E8>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/9275cb2810455b73fd0f736eeff3b862\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001160CBCA208>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/9275cb2810455b73fd0f736eeff3b862\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001160CBCA780>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')': /session/9275cb2810455b73fd0f736eeff3b862\n",
      "C:\\Users\\JChaotogo\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: use options instead of chrome_options\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "driver.quit()\n",
    "useragent = agents['0'][58]\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(f\"user-agent={useragent}\")\n",
    "options.add_argument('--incognito')\n",
    "chromedriver = '~/Downloads/chromedriver'\n",
    "chromedriver = os.path.expanduser(chromedriver)\n",
    "driver = webdriver.Chrome(chromedriver, chrome_options=options)\n",
    "driver.delete_all_cookies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to collect URLs\n",
    "Collects URLs for the listings that I wanted to analyze. Also contains functions that I needed in order to make various clicks as well as notify me of a captcha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_house_links(url, driver, pages=20):\n",
    "    house_links=[]\n",
    "    driver.get(url)\n",
    "    for i in range(pages):\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        time.sleep(np.random.lognormal(0,1))\n",
    "        listings = soup.find_all(\"a\", class_=\"zsg-photo-card-overlay-link\")\n",
    "        page_data = ['https://www.zillow.com'+row['href'] for row in listings]\n",
    "        house_links.append(page_data)\n",
    "        next_button = soup.find_all(\"a\", class_=\"on\")\n",
    "        next_button_link = ['https://www.zillow.com'+row['href'] for row in next_button]\n",
    "        if i<19:\n",
    "            time.sleep(2)\n",
    "            WebDriverWait(driver,5).until(EC.presence_of_element_located((By.CLASS_NAME , 'zsg-pagination-next'))).click()\n",
    "\n",
    "\n",
    "    return house_links\n",
    "\n",
    "def get_html_data(url, driver):\n",
    "    driver.get(url)\n",
    "    time.sleep(np.random.lognormal(0,1))\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def flatten_list(house_links):\n",
    "    house_links_flat=[]\n",
    "    for sublist in house_links:\n",
    "        for item in sublist:\n",
    "            house_links_flat.append(item)\n",
    "    return house_links_flat\n",
    "\n",
    "def _is_element_displayed(driver, elem_text, elem_type):\n",
    "    if elem_type == \"class\":\n",
    "        try:\n",
    "            out = driver.find_element_by_class_name(elem_text).is_displayed()\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            out = False\n",
    "    elif elem_type == \"css\":\n",
    "        try:\n",
    "            out = driver.find_element_by_css_selector(elem_text).is_displayed()\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            out = False\n",
    "    else:\n",
    "        raise ValueError(\"arg 'elem_type' must be either 'class' or 'css'\")\n",
    "    return(out)\n",
    "\n",
    "\n",
    "def _pause_for_captcha(driver):\n",
    "    while True:\n",
    "        time.sleep(10)\n",
    "        if not _is_element_displayed(driver, \"captcha-container\", \"class\"):\n",
    "            break\n",
    "\n",
    "# Check to see if the page is currently stuck on a captcha page. If so, pause \n",
    "# the scraper until user has manually completed the captcha requirements.\n",
    "def check_for_captcha(driver):\n",
    "    if _is_element_displayed(driver, \"captcha-container\", \"class\"):\n",
    "        print(\"\\nCAPTCHA!\\n\"\\\n",
    "              \"Manually complete the captcha requirements.\\n\"\\\n",
    "              \"Once that's done, if the program was in the middle of scraping \"\\\n",
    "              \"(and is still running), it should resume scraping after ~30 seconds.\")\n",
    "        _pause_for_captcha(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for specific information\n",
    "\n",
    "There were 2 formats for some listing pages. I wrote functions for both and used try and except to choose the correct functions to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tax(driver):\n",
    "    try:\n",
    "        WebDriverWait(driver,20).until(EC.presence_of_element_located((By.ID , 'price-and-tax-history'))).click()\n",
    "        tabs = WebDriverWait(driver,5).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".zsg-tab-link\")))\n",
    "        tabs[1].click()\n",
    "        text = driver.find_element_by_css_selector('#hdp-tax-history table').text\n",
    "        tax = text.split('\\n')[1]\n",
    "        return tax\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_percent_increase(driver):\n",
    "    try:\n",
    "        WebDriverWait(driver,20).until(EC.presence_of_element_located((By.ID , 'homeValue'))).click()\n",
    "        text = driver.find_element_by_class_name('secondary-zestimate-items').text\n",
    "        forecast = text.split('\\n')[-1]\n",
    "        return forecast\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_hoa_fee(soup):\n",
    "    try:\n",
    "        hoa = re.findall('HOA Fee\",\"factValue\":\"\\$[0-9]{2,3}', soup.text)\n",
    "        return hoa\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_numbaths(soup):\n",
    "    try:\n",
    "        baths = soup.find('h3', class_='edit-facts-light')\n",
    "        baths = baths.find_all('span')[3].text\n",
    "        baths = baths.replace('baths', '').lower().strip()\n",
    "        return float(baths)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def get_numbeds(soup):\n",
    "    try:\n",
    "        beds = soup.find('h3', class_='edit-facts-light')\n",
    "        beds = beds.find_all('span')[1].text\n",
    "        beds = beds.replace('beds', '').lower().strip()\n",
    "        return float(beds)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_floor_size(soup):\n",
    "    try:\n",
    "        sqft = soup.find('h3', class_='edit-facts-light')\n",
    "        sqft = sqft.find_all('span')[5].text\n",
    "        sqft = sqft.replace('sqft', '').replace(',', '').lower().strip()\n",
    "        return sqft\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_lot_size(soup):\n",
    "    try:\n",
    "        price = soup.find_all('div', class_='zestimate-value')[5].text\n",
    "        price = price.replace(',', '').replace('sqft', '').lower().strip()\n",
    "        return int(price)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_property_type(soup):\n",
    "    try:\n",
    "        price = soup.find_all('div', class_='fact-value')[0].text\n",
    "        price = price.lower().strip()\n",
    "        return str(price)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_year_built(soup):\n",
    "    try:\n",
    "        price = soup.find_all('div', class_='fact-value')[1].text\n",
    "        price = price.lower().strip()\n",
    "        return int(price)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_zestimate(soup):\n",
    "    try:\n",
    "        price = soup.find('div', class_='zestimate-value').text\n",
    "        return price\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def get_rent(soup):\n",
    "    try:\n",
    "        price = soup.find_all('div', class_='toggle-section')[-1]\n",
    "        price = price.find('div', class_='zestimate-value').text\n",
    "        return price\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def get_sale_price(soup):\n",
    "    try:\n",
    "        price = soup.find('span', class_='value').text\n",
    "        price = price.replace('$', '').replace(',', '').lower().strip()\n",
    "        return int(price)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "    \n",
    "def get_zip(soup):\n",
    "    try:\n",
    "        zipcode = soup.find('div', class_='zsg-h2').text\n",
    "        zipcode = re.search('[0-9]{5}', zipcode)\n",
    "        zipcode = zipcode.group(0)\n",
    "        return int(zipcode)\n",
    "    except:\n",
    "        return 'None'\n",
    "    \n",
    "def get_address(soup):\n",
    "    try:\n",
    "        address = soup.find('div', class_='zsg-h1 hdp-home-header-st-addr').text.strip().lower()\n",
    "        return address\n",
    "    except:\n",
    "        return 'None'\n",
    "\n",
    "    \n",
    "def get_city(soup):\n",
    "    try:\n",
    "        city = soup.find('div', class_='zsg-h2').text.strip().lower()\n",
    "        city = city.split(',')[0]\n",
    "        return str(city)\n",
    "    except:\n",
    "        return 'None'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_zestimate1(soup):\n",
    "    try:\n",
    "        zest = soup.find_all('h4', class_='zestimate-value')\n",
    "        zestimate = zest[0].text\n",
    "        rent = zest[1].text\n",
    "        return zestimate, rent\n",
    "    except:\n",
    "        return np.nan, np.nan\n",
    "def get_bed_bath_live1(soup):\n",
    "    try:\n",
    "        info = soup.find('h3', class_='ds-bed-bath-living-area-container')\n",
    "        info = info.find_all('span')\n",
    "        beds = info[0].text\n",
    "        baths= info[3].text\n",
    "        sqft = info[6].text\n",
    "        return beds, baths, sqft\n",
    "    except:\n",
    "        return np.nan, np.nan, np,nan\n",
    "def get_tax1(soup):\n",
    "    try:\n",
    "        tax = soup.find('tr', class_='ds-tax-table-row').text\n",
    "        return tax\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def get_hoa1(soup):\n",
    "    try:\n",
    "        hoa = soup.find_all('div', class_='sc-jKJlTe loXQau')[4].text\n",
    "        return hoa\n",
    "    except:\n",
    "        return np.nan\n",
    "def get_percent_increase1(soup):\n",
    "    try:\n",
    "        percent = soup.find_all('span', class_='percent-increase')[-1].text\n",
    "        return percent\n",
    "    except:\n",
    "        return np.nan\n",
    "def get_sale_price1(soup):\n",
    "    try:\n",
    "        price = soup.find('span', class_='ds-value').text\n",
    "        return price\n",
    "    except:\n",
    "        return np.nan\n",
    "def get_property_type1(soup):\n",
    "    try:\n",
    "        prop = soup.find('span', class_='ds-body ds-home-fact-value').text\n",
    "        return prop\n",
    "    except:\n",
    "        return np.nan\n",
    "def get_year_built1(soup):\n",
    "    try:\n",
    "        year = soup.find_all('span', class_='ds-body ds-home-fact-value')[1].text\n",
    "        return year\n",
    "    except:\n",
    "        return np.nan\n",
    "def get_address1(soup):\n",
    "    try:\n",
    "        full = soup.find('h1', class_='ds-address-container')\n",
    "        address = full.find_all('span')[0].text\n",
    "        city = full.find_all('span')[1].text.split(',')[0]\n",
    "        zipcode = full.find_all('span')[1].text\n",
    "        zipcode = re.findall('[0-9]{5}', zipcode)\n",
    "        return address, city, zipcode\n",
    "    except:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "def get_house_data1(driver, house_links_flat, houselist):\n",
    "    for link in tqdm(house_links_flat):\n",
    "        soup = get_html_data(link, driver)\n",
    "        check_for_captcha(driver)\n",
    "        try:\n",
    "            address, city, zipcode = get_address1(soup)\n",
    "            beds, baths, sqft = get_bed_bath_live1(soup)\n",
    "            year = get_year_built1(soup)\n",
    "            saleprice = get_sale_price1(soup)\n",
    "            zestimate, rent = get_zestimate1(soup)\n",
    "            property_type = get_property_type1(soup)\n",
    "            tax = get_tax1(soup)\n",
    "            hoa = get_hoa1(soup)\n",
    "            percent_increase = get_percent_increase1(soup)\n",
    "            houselist.append([address, city, zipcode, beds, baths, sqft, year,\n",
    "                             saleprice, zestimate, rent, property_type, hoa,\n",
    "                             tax, percent_increase, link])\n",
    "            time.sleep(np.random.lognormal(0,1)+2)\n",
    "        except:\n",
    "            city = get_city(soup)\n",
    "            zipcode = get_zip(soup)\n",
    "            beds = get_numbeds(soup)\n",
    "            baths = get_numbaths(soup)\n",
    "            floor_size = get_floor_size(soup)\n",
    "            year_built = get_year_built(soup)\n",
    "            saleprice = get_sale_price(soup)\n",
    "            rent = re.findall('\"rentZestimate\":[0-9]{3,4}', soup.text)\n",
    "            zestimate = re.findall('\"zestimate\":[0-9]{5,8}', soup.text)\n",
    "            property_type = get_property_type(soup)\n",
    "            tax = get_tax(driver)\n",
    "            hoa = get_hoa_fee(soup)\n",
    "            check_for_captcha(driver)\n",
    "            percent_increase = get_percent_increase(driver)\n",
    "            houselist.append([address, city, zipcode, beds, baths, floor_size, year_built, saleprice, zestimate,\n",
    "                              rent, property_type, hoa, tax, percent_increase, link])\n",
    "            time.sleep(np.random.lognormal(0,1)+2)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "fortworthurl = 'https://www.zillow.com/homes/for_sale/Austin-TX/house,condo,apartment_duplex,townhouse_type/10221_rid/2-_beds/100000-325000_price/393-1279_mp/1960-_built/0-100_hoa/globalrelevanceex_sort/30.538016,-97.416459,30.048887,-98.154603_rect/10_zm/'\n",
    "fort20 = get_house_links(fortworthurl, driver, pages=20)\n",
    "austinlinks = flatten_list(fort20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlantahomes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 1/14 [00:17<03:46, 17.42s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 2/14 [00:32<03:21, 16.83s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|██▏       | 3/14 [00:49<03:03, 16.66s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██▊       | 4/14 [01:02<02:36, 15.68s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 5/14 [01:17<02:18, 15.34s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 6/14 [01:28<01:53, 14.19s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 7/14 [01:38<01:30, 12.90s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 8/14 [01:49<01:14, 12.46s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|██████▍   | 9/14 [02:02<01:02, 12.42s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████▏  | 10/14 [02:13<00:48, 12.18s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|███████▊  | 11/14 [02:25<00:36, 12.17s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████▌ | 12/14 [02:41<00:26, 13.22s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 13/14 [02:54<00:13, 13.24s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 14/14 [03:12<00:00, 14.67s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_house_data1(driver, atlantalinks[486:], atlantahomes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
